{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GSN_2 Laboratorium 2.ipnyb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/iis-siium/GSN_2_zima_2020/blob/master/GSN_2_Laboratorium_1.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwfqH0O7xItI"
      },
      "source": [
        "%tensorflow_version 1.x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdBrkGDfyoYt"
      },
      "source": [
        "# https://github.com/blueberrymusic/DeepLearningBookCode-Volume1\n",
        "!wget https://raw.githubusercontent.com/blueberrymusic/DeepLearningBookCode-Volume1/master/DLBasics_Utilities/DLBasics_Utilities.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ZWDrDawkrQ"
      },
      "source": [
        "# Harvard University\n",
        "# CS109B Data Science 2: Advanced Topics in Data Science\n",
        "# Spring 2019\n",
        "# Instructors: Mark Glickman and Pavlos Protopapas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfHBLwhkxiYv"
      },
      "source": [
        "#RUN THIS CELL \n",
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
        "HTML(styles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LfgbFPsxtoc"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "#import h5py\n",
        "#from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EMqFAAuxwDP"
      },
      "source": [
        "# I will be saving everything so I can re-use them \n",
        "save_files = True\n",
        "\n",
        "import os, sys, inspect\n",
        "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
        "from DLBasics_Utilities import File_Helper\n",
        "file_helper = File_Helper(save_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ7VW9WixwxC"
      },
      "source": [
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Read MNIST data. Of course we will not be using y_train and y_test\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Full size of the image 28x28 \n",
        "N_pixels = X_train.shape[1]*X_train.shape[2]\n",
        "\n",
        "# Convert to floats\n",
        "X_train = keras_backend.cast_to_floatx(X_train)\n",
        "X_test = keras_backend.cast_to_floatx(X_test)\n",
        "\n",
        "# Normalize the range from [0,255] to [0,1]\n",
        "X_train /= 255.\n",
        "X_test /= 255.\n",
        "\n",
        "# Reshape the data into a grid with one row per sample, each row 784 (28*28) pixels\n",
        "X_train = X_train.reshape((len(X_train), N_pixels))\n",
        "X_test = X_test.reshape((len(X_test), N_pixels))\n",
        "\n",
        "print(\"X_train.shape = \",X_train.shape, \" X_test.shape = \",X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD3vbV5Sxw2b"
      },
      "source": [
        "def draw_predictions_set(predictions, filename=None):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    for i in range(5):\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(X_test[i].reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
        "        ax = plt.gca()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        plt.subplot(2, 5, i+6)\n",
        "        plt.imshow(predictions[i].reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
        "        ax = plt.gca()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    file_helper.save_figure(filename+'-predictions')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MTaTzX-xw5k"
      },
      "source": [
        "# Build and train our first autoencoder\n",
        "num_latent_vars = 20\n",
        "\n",
        "modelAE1 = Sequential()\n",
        "modelAE1.add(Dense(num_latent_vars, input_dim=N_pixels, activation='relu'))\n",
        "modelAE1.add(Dense(N_pixels, activation='linear'))\n",
        "modelAE1.compile(optimizer='adadelta', loss='mse')\n",
        "\n",
        "\n",
        "weights_filename = \"modelAE1-weights\"\n",
        "np.random.seed(52)\n",
        "\n",
        "if not file_helper.load_model_weights(modelAE1, weights_filename):\n",
        "    modelAE1.fit(X_train, X_train,\n",
        "                   epochs=20, batch_size=128, shuffle=True,\n",
        "                   verbose=2,\n",
        "                   validation_data=(X_test, X_test))\n",
        "    file_helper.save_model_weights(modelAE1, weights_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxYZCRhzxw8k"
      },
      "source": [
        "predictions1 = modelAE1.predict(X_test)\n",
        "draw_predictions_set(predictions1, 'FCC1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D48E9-5Zxw_I"
      },
      "source": [
        "# Build and train our first autoencoder\n",
        "num_latent_vars = 20\n",
        "\n",
        "modelAE1_s = Sequential()\n",
        "modelAE1_s.add(Dense(num_latent_vars, input_dim=N_pixels, activation='relu'))\n",
        "modelAE1_s.add(Dense(N_pixels, activation='sigmoid'))\n",
        "modelAE1_s.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "\n",
        "weights_filename = \"modelAE1-weights-sigmoid\"\n",
        "np.random.seed(52)\n",
        "if not file_helper.load_model_weights(modelAE1_s, weights_filename):\n",
        "    modelAE1_s.fit(X_train, X_train,\n",
        "                   epochs=20, batch_size=128, shuffle=True,\n",
        "                   verbose=2,\n",
        "                   validation_data=(X_test, X_test))\n",
        "    file_helper.save_model_weights(modelAE1_s, weights_filename)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVTAxzaExxBw"
      },
      "source": [
        "predictions1 = modelAE1_s.predict(X_test)\n",
        "draw_predictions_set(predictions1, 'FCC1-s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAXRyvrvxxEU"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "filepath = file_helper.get_input_file_path(\"pavlos-gray-28-28.png\")\n",
        "im = Image.open(filepath) \n",
        "pix = im.load()\n",
        "pavlos = np.zeros((1,784))\n",
        "for y in range(28):\n",
        "    for x in range(28):\n",
        "        pavlos[0,(y*28)+x] = pix[x,y][0]/255.\n",
        "        \n",
        "predicted_pavlos = modelAE1_s.predict(pavlos)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(np.reshape(pavlos, (28, 28)), vmin=0, vmax=1, cmap=\"gray\")\n",
        "ax = plt.gca()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.reshape(predicted_pavlos, (28, 28)), vmin=0, vmax=1, cmap=\"gray\")\n",
        "ax = plt.gca()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "plt.tight_layout()\n",
        "file_helper.save_figure('Model-FCC-pavlos-pair')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsSsQ9_NxxHV"
      },
      "source": [
        "# rebuild model with the Functional API so we can play with the decoder alone\n",
        "from keras.layers import Input\n",
        "\n",
        "num_latent_vars = 20\n",
        "\n",
        "model_encoder_input = Input(shape=(784,))\n",
        "model_encoder_512 = Dense(512, activation='relu')\n",
        "model_encoder_256 = Dense(256, activation='relu')\n",
        "model_encoder_latent = Dense(num_latent_vars, activation='relu')\n",
        "\n",
        "model_decoder_256 = Dense(256, activation='relu')\n",
        "model_decoder_512 = Dense(512, activation='relu')\n",
        "model_decoder_out = Dense(784, activation='sigmoid')\n",
        "\n",
        "model_encoder_step_1 = model_encoder_512(model_encoder_input)\n",
        "model_encoder_step_2 = model_encoder_256(model_encoder_step_1)\n",
        "model_encoder_output = model_encoder_latent(model_encoder_step_2)\n",
        "\n",
        "model_decoder_step_1 = model_decoder_256(model_encoder_output)\n",
        "model_decoder_step_2 = model_decoder_512(model_decoder_step_1)\n",
        "model_decoder_output = model_decoder_out(model_decoder_step_2)\n",
        "\n",
        "model_AE_F = Model(model_encoder_input, model_decoder_output)\n",
        "\n",
        "model_encoder_only_model = Model(model_encoder_input, model_encoder_output)\n",
        "\n",
        "model_decoder_only_input = Input(shape=(num_latent_vars,))\n",
        "model_decoder_only_step_1 = model_decoder_256(model_decoder_only_input)\n",
        "model_decoder_only_step_2 = model_decoder_512(model_decoder_only_step_1)\n",
        "model_decoder_only_output = model_decoder_out(model_decoder_only_step_2)\n",
        "model_decoder_only_model = Model(model_decoder_only_input, model_decoder_only_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd2AuGDhxxQT"
      },
      "source": [
        "model_AE_F.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "weights_filename = \"model-AE-F-weights\"\n",
        "np.random.seed(52)\n",
        "if not file_helper.load_model_weights(model_AE_F, weights_filename):\n",
        "    model_AE_F.fit(X_train, X_train,\n",
        "               epochs=20, batch_size=128, shuffle=True,\n",
        "               verbose=2,\n",
        "               validation_data=(X_test, X_test))\n",
        "    file_helper.save_model_weights(model_AE_F, weights_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz9tFbN4xxWj"
      },
      "source": [
        "# show the input data, its latent values, and the corresponding predicted images\n",
        "np.random.seed(random_seed)\n",
        "encoder_predictions = model_encoder_only_model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "latent_min = np.min(encoder_predictions[0:5])\n",
        "latent_max = np.max(encoder_predictions[0:5])\n",
        "for i in range(5):\n",
        "    plt.subplot(3, 5, i+1)\n",
        "    plt.imshow(X_test[i].reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
        "    ax = plt.gca()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    plt.subplot(3, 5, i+6)\n",
        "    plt.bar(np.arange(len(encoder_predictions[i])), encoder_predictions[i])\n",
        "    plt.xticks([], [])\n",
        "    plt.ylim(latent_min, latent_max)\n",
        "    \n",
        "    plt.subplot(3, 5, i+11)\n",
        "    decoder_model_input = np.resize(encoder_predictions[i], (1, len(encoder_predictions[i])))\n",
        "    decoder_prediction = model_decoder_only_model.predict(decoder_model_input)\n",
        "    plt.imshow(decoder_prediction.reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
        "    ax = plt.gca()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.tight_layout()\n",
        "file_helper.save_figure(\"model-F-latents-and-output\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKRYhEKqyGoY"
      },
      "source": [
        "# show the latent values and the corresponding predicted images\n",
        "# this makes big vertical spaces between the \n",
        "def show_latents_and_predictions(predictions, filename=None):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    latent_min = np.min(predictions[0:5])\n",
        "    latent_max = np.max(predictions[0:5])\n",
        "    for i in range(5):\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.bar(np.arange(len(predictions[i])), predictions[i])\n",
        "        plt.xticks([], [])\n",
        "        plt.ylim(latent_min, latent_max)\n",
        "\n",
        "        plt.subplot(2, 5, i+6)\n",
        "        decoder_model_input = np.resize(predictions[i], (1, len(predictions[i])))\n",
        "        decoder_prediction = model_decoder_only_model.predict(decoder_model_input)\n",
        "        plt.imshow(decoder_prediction.reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
        "        ax = plt.gca()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    file_helper.save_figure(filename)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD5j3c2ryGrG"
      },
      "source": [
        "# add [-noise to all values\n",
        "encoder_predictions = np.array(model_encoder_only_model.predict(X_test))\n",
        "np.random.seed(random_seed)\n",
        "noise = 10\n",
        "for i in range(encoder_predictions.shape[0]):\n",
        "    for j in range(len(encoder_predictions[i])):\n",
        "        encoder_predictions[i][j] += np.random.uniform(low=-noise, high=noise)\n",
        "show_latents_and_predictions(encoder_predictions, 'NB2-MLP-AE5-prediction-latent-values-with-noise-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWVxRmnOyGtv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP3PP2HSyGwU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6FNXLEyPmZH"
      },
      "source": [
        "Convolutional Autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfCESR3xyGyy"
      },
      "source": [
        "from keras import callbacks\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEpEu4ZCPqMD"
      },
      "source": [
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "# x_train = (x_train.astype('float32') - 127.5) / 127.5\n",
        "# x_test = (x_test.astype('float32') - 127.5) / 127.5\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "# # Encoder architecture 1\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "encoded_input = Input(shape=(4, 4, 8))\n",
        "deco = autoencoder.layers[-7](encoded_input)\n",
        "deco = autoencoder.layers[-6](deco)\n",
        "deco = autoencoder.layers[-5](deco)\n",
        "deco = autoencoder.layers[-4](deco)\n",
        "deco = autoencoder.layers[-3](deco)\n",
        "deco = autoencoder.layers[-2](deco)\n",
        "deco = autoencoder.layers[-1](deco)\n",
        "decoder = Model(encoded_input, deco)\n",
        "\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "# # Encoder architecture 2\n",
        "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "# x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "# encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "#\n",
        "# encoder = Model(input_img, encoded)\n",
        "#\n",
        "# # at this point the representation is (7, 7, 32)\n",
        "#\n",
        "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "# x = UpSampling2D((2, 2))(x)\n",
        "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = UpSampling2D((2, 2))(x)\n",
        "# decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "#\n",
        "# autoencoder = Model(input_img, decoded)\n",
        "# autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w8qYvzUPqH9"
      },
      "source": [
        "\n",
        "num_epochs = 1\n",
        "checkpoints = ModelCheckpoint('tmp/checkpoint_autoencoder.h5', save_best_only=True)\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=num_epochs,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='tmp/autoencoder'), ModelCheckpoint('tmp/checkpoint_autoencoder.h5', save_best_only=True)])\n",
        "\n",
        "encoder.save(\"conv_encoder.h5\")\n",
        "decoder.save(\"conv_decoder.h5\")\n",
        "autoencoder.save(\"conv_autoenoder.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qKDM66EPqDy"
      },
      "source": [
        "# generate only encoded representation of the images - for future use in other algorithms\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "# using full autoencoder\n",
        "# decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# using decoder built from some layers of autoencoder\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i+1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i+1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF4mcViAPp-0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kHa-J6CPp1O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-yWifR8wthA"
      },
      "source": [
        "# !pip install imgaug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYP8qbGFxs6z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H61MRypUwyBF"
      },
      "source": [
        "## load the libraries \n",
        "import sys\n",
        "import warnings\n",
        "import os\n",
        "import glob\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Sequential\n",
        "from keras.metrics import *\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from scipy.stats import norm\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from imgaug import augmenters\n",
        "import matplotlib.pyplot as plt\n",
        "plt.gray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8MumOtiw7en"
      },
      "source": [
        "# ### read dataset \n",
        "# train = pd.read_csv(\"data/fashion-mnist_train.csv\")\n",
        "# train_x = train[list(train.columns)[1:]].values\n",
        "# train_x, val_x = train_test_split(train_x, test_size=0.15)\n",
        "\n",
        "# ## create train and validation datasets\n",
        "# train_x, val_x = train_test_split(train_x, test_size=0.15)\n",
        "\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
        "\n",
        "train_x, val_x = train_test_split(train_x, test_size=0.15)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSMzA23OxOSz"
      },
      "source": [
        "## normalize and reshape\n",
        "train_x = train_x/255.\n",
        "val_x = val_x/255.\n",
        "\n",
        "train_x = train_x.reshape(-1, 28, 28, 1)\n",
        "val_x = val_x.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcXaejCAxPZO"
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIlDDhNKxRDD"
      },
      "source": [
        "f, ax = plt.subplots(1,5)\n",
        "f.set_size_inches(80, 40)\n",
        "for i in range(5,10):\n",
        "    ax[i-5].imshow(train_x[i, :, :, 0].reshape(28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le24EOSZRx1L"
      },
      "source": [
        "## Add Noise to Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl41zoDxRZCN"
      },
      "source": [
        "# Lets add sample noise - Salt and Pepper\n",
        "noise = augmenters.SaltAndPepper(0.1)\n",
        "seq_object = augmenters.Sequential([noise])\n",
        "\n",
        "train_x_n = seq_object.augment_images(train_x * 255) / 255\n",
        "val_x_n = seq_object.augment_images(val_x * 255) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ii6g-U7Rl00"
      },
      "source": [
        "f, ax = plt.subplots(1,5)\n",
        "f.set_size_inches(80, 40)\n",
        "for i in range(5,10):\n",
        "    ax[i-5].imshow(train_x_n[i, :, :, 0].reshape(28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dlaADk5RZIn"
      },
      "source": [
        "# input layer\n",
        "input_layer = Input(shape=(28, 28, 1))\n",
        "\n",
        "# encoding architecture\n",
        "encoded_layer1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "encoded_layer1 = MaxPool2D( (2, 2), padding='same')(encoded_layer1)\n",
        "encoded_layer2 = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded_layer1)\n",
        "encoded_layer2 = MaxPool2D( (2, 2), padding='same')(encoded_layer2)\n",
        "encoded_layer3 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded_layer2)\n",
        "latent_view    = MaxPool2D( (2, 2), padding='same')(encoded_layer3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUE2ImJKR81t"
      },
      "source": [
        "## Setup Encoder Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5EmPuMtRZTx"
      },
      "source": [
        "# input layer\n",
        "input_layer = Input(shape=(28, 28, 1))\n",
        "\n",
        "# encoding architecture\n",
        "encoded_layer1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "encoded_layer1 = MaxPool2D( (2, 2), padding='same')(encoded_layer1)\n",
        "encoded_layer2 = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded_layer1)\n",
        "encoded_layer2 = MaxPool2D( (2, 2), padding='same')(encoded_layer2)\n",
        "encoded_layer3 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded_layer2)\n",
        "latent_view    = MaxPool2D( (2, 2), padding='same')(encoded_layer3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqcwDjP2SDfh"
      },
      "source": [
        "# Setup Decoder Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3IJvLR8RZcm"
      },
      "source": [
        "# decoding architecture\n",
        "decoded_layer1 = Conv2D(16, (3, 3), activation='relu', padding='same')(latent_view)\n",
        "decoded_layer1 = UpSampling2D((2, 2))(decoded_layer1)\n",
        "decoded_layer2 = Conv2D(32, (3, 3), activation='relu', padding='same')(decoded_layer1)\n",
        "decoded_layer2 = UpSampling2D((2, 2))(decoded_layer2)\n",
        "decoded_layer3 = Conv2D(64, (3, 3), activation='relu')(decoded_layer2)\n",
        "decoded_layer3 = UpSampling2D((2, 2))(decoded_layer3)\n",
        "output_layer   = Conv2D(1, (3, 3), padding='same')(decoded_layer3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3RzH7FrRZk_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofoqWstiSPfq"
      },
      "source": [
        "## Train AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrHs6NnHRZuK"
      },
      "source": [
        "# compile the model\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIqswiHLRZzQ"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')\n",
        "history = model.fit(train_x_n, train_x, epochs=20, batch_size=2048, validation_data=(val_x_n, val_x), callbacks=[early_stopping])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t6lNNxpScae"
      },
      "source": [
        "## Visualize Intermediate Layers of AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-imlNNQRZsh"
      },
      "source": [
        "# compile the model\n",
        "model_2 = Model(input_layer, latent_view)\n",
        "model_2.compile(optimizer='adam', loss='mse')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRdYFGHRZqD"
      },
      "source": [
        "n = np.random.randint(0,len(val_x)-5)\n",
        "f, ax = plt.subplots(1,5)\n",
        "f.set_size_inches(80, 40)\n",
        "for i,a in enumerate(range(n,n+5)):\n",
        "    ax[i].imshow(val_x_n[a, :, :, 0].reshape(28, 28))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6m7aJ3SRZiY"
      },
      "source": [
        "preds = model_2.predict(val_x_n[n:n+5])\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne8bnF7KRZgU"
      },
      "source": [
        "f, ax = plt.subplots(16,5)\n",
        "ax = ax.ravel()\n",
        "f.set_size_inches(20, 40)\n",
        "for j in range(16):\n",
        "    for i,a in enumerate(range(n,n+5)):\n",
        "        ax[j*5 + i].imshow(preds[i, :, :, j])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QTX9DrdRZbA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhSe8KqBStOY"
      },
      "source": [
        "## Visualize Samples reconstructed by AE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVRHmhFARZYh"
      },
      "source": [
        "n = np.random.randint(0,len(val_x)-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvlCbx4URZR5"
      },
      "source": [
        "f, ax = plt.subplots(1,5)\n",
        "f.set_size_inches(80, 40)\n",
        "for i,a in enumerate(range(n,n+5)):\n",
        "    ax[i].imshow(val_x[a, :, :, 0].reshape(28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMPXUw8KRZOG"
      },
      "source": [
        "preds = model.predict(val_x_n[n:n+5])\n",
        "f, ax = plt.subplots(1,5)\n",
        "f.set_size_inches(80, 40)\n",
        "for i,a in enumerate(range(n,n+5)):\n",
        "    ax[i].imshow(preds[i].reshape(28, 28))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}