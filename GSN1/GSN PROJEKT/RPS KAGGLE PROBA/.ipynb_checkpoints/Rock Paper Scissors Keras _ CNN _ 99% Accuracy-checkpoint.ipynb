{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2c21eedd4de2b65f523e8e387012f6b20db923a"
   },
   "source": [
    "# Project Page\n",
    "### Here is the link to the project page for this dataset\n",
    "### https://github.com/DrGFreeman/rps-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'imread' from 'scipy.ndimage' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d8d57453233e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmisc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'imread' from 'scipy.ndimage' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#-------Import Dependencies-------#\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os,shutil,math,scipy,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rn\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import Image as pil_image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from time import time\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "from IPython.display import SVG\n",
    "\n",
    "from scipy import misc,ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\n",
    "from keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b39206d206c0d67d6a5ff34c2ff69336907f4e65"
   },
   "source": [
    "# Function for training visualization\n",
    "### Here is a function I create to visualize the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30558cdfd5f7f7949bd0a04cdbd13f7b739189f9"
   },
   "outputs": [],
   "source": [
    "def show_final_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('acc')\n",
    "    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84700e29c4dd3a545ac6faf8200e7e0c54198ea6"
   },
   "source": [
    "# Image Preprocessing\n",
    "### Here I use the data augmentation and image preprocessing from the Keras ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac321de75cfed2980da8aad5cc0e20c1c78d5588"
   },
   "outputs": [],
   "source": [
    "data_dir = '../input/rps-cv-images/'\n",
    "augs_gen = ImageDataGenerator(\n",
    "    rescale=1./255,        \n",
    "    horizontal_flip=True,\n",
    "    height_shift_range=.2,\n",
    "    vertical_flip = True,\n",
    "    validation_split = 0.2\n",
    ")  \n",
    "\n",
    "train_gen = augs_gen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size = (224,224),\n",
    "    batch_size=32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_gen = augs_gen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2ef96f27b5123489c3db66426f16816366ff39f"
   },
   "source": [
    "# The Model\n",
    "### Here I use the pretrained mobile net.\n",
    "### I used this architecture because I plan to make this into a web app\n",
    "### https://keras.io/applications/#mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80f3b87562efe445fb5c0eca507748c51b1f1a60"
   },
   "outputs": [],
   "source": [
    "model_base = MobileNet(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "model = Sequential()\n",
    "model.add(model_base)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0,5))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "525c9509fb997b2be96426f56a342ff17540afb0"
   },
   "source": [
    "# Callbacks\n",
    "### Here I load my Keras Callbacks to monitor the training of the model\n",
    "### https://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69444168ff80c96381a47bf0482023cfa3c92112"
   },
   "outputs": [],
   "source": [
    "#-------Callbacks-------------#\n",
    "best_model_weights = './base.model'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    best_model_weights,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=False,\n",
    "    period=1\n",
    ")\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir = './logs',\n",
    "    histogram_freq=0,\n",
    "    batch_size=16,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=False,\n",
    ")\n",
    "\n",
    "csvlogger = CSVLogger(\n",
    "    filename= \"training_csv.log\",\n",
    "    separator = \",\",\n",
    "    append = False\n",
    ")\n",
    "\n",
    "#lrsched = LearningRateScheduler(step_decay,verbose=1)\n",
    "\n",
    "reduce = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=40,\n",
    "    verbose=1, \n",
    "    mode='auto',\n",
    "    cooldown=1 \n",
    ")\n",
    "\n",
    "callbacks = [checkpoint,tensorboard,csvlogger,reduce]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0f23f1bd99f3359d4880ba8c4ae74f4d2ea280e"
   },
   "source": [
    "# Train The Model\n",
    "### Here I train our model using fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72fd3605a604ca990bab8c9e87d89ea3171635aa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = SGD(lr=1e-4,momentum=0.99)\n",
    "opt1 = Adam(lr=2e-4)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "    \n",
    "history = model.fit_generator(\n",
    "    train_gen, \n",
    "    steps_per_epoch  = 50, \n",
    "    validation_data  = val_gen,\n",
    "    validation_steps = 50,\n",
    "    epochs = 5, \n",
    "    verbose = 1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2cd33bed7431aeb30921fa01032304b2068bb5a"
   },
   "source": [
    "# Model Evaluation\n",
    "### Here I visualize the training results, load the best model weights, evalute the model, save the json file and h5 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9875bf81a6591348565e02eeaa6d97d99e653883"
   },
   "outputs": [],
   "source": [
    "show_final_history(history)\n",
    "model.load_weights(best_model_weights)\n",
    "model_score = model.evaluate_generator(val_gen,steps=20)\n",
    "print(\"Model Test Loss:\",model_score[0])\n",
    "print(\"Model Test Accuracy:\",model_score[1])\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save(\"model.h5\")\n",
    "print(\"Weights Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a25901b1c24f0bfc1fcdd78ee2e9027b238b08c2"
   },
   "source": [
    "# TensorBoard\n",
    "### Here is a script that you can use with the TensorBoard Keras Callback. It will give you a URL to view your models training results on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6afb297e1b8d691f9d190277c41a04e42325db52"
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "LOG_DIR = './logs' # Here you have to put your log directory\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 8080 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "459994972c915591976a584e31aeea382c3a4f4f"
   },
   "source": [
    "# Happy Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31fa95efdbe84651d34d2192a798030aca45d42b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
