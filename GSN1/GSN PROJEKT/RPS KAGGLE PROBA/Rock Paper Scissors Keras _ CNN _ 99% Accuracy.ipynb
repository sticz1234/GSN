{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2c21eedd4de2b65f523e8e387012f6b20db923a"
   },
   "source": [
    "# Project Page\n",
    "### Here is the link to the project page for this dataset\n",
    "### https://github.com/DrGFreeman/rps-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-------Import Dependencies-------#\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os,shutil,math,scipy,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rn\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import Image as pil_image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from time import time\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "from IPython.display import SVG\n",
    "\n",
    "from scipy import misc,ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "#from scipy.ndimage import imread\n",
    "\n",
    "from imageio import imread   # ZMIANA !!\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\n",
    "from keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b39206d206c0d67d6a5ff34c2ff69336907f4e65"
   },
   "source": [
    "# Function for training visualization\n",
    "### Here is a function I create to visualize the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "30558cdfd5f7f7949bd0a04cdbd13f7b739189f9"
   },
   "outputs": [],
   "source": [
    "def show_final_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('acc')\n",
    "    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84700e29c4dd3a545ac6faf8200e7e0c54198ea6"
   },
   "source": [
    "# Image Preprocessing\n",
    "### Here I use the data augmentation and image preprocessing from the Keras ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ac321de75cfed2980da8aad5cc0e20c1c78d5588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2188 images belonging to 3 classes.\n",
      "Found 437 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"C:\\Users\\sticz\\Desktop\\Pytong\\GSN PROJEKT\\Obrazy\\rps-cv-images\"\n",
    "\n",
    "augs_gen = ImageDataGenerator(\n",
    "    rescale=1./255,        \n",
    "    horizontal_flip=True,\n",
    "    height_shift_range=.2,\n",
    "    vertical_flip = True,\n",
    "    validation_split = 0.2\n",
    ")  \n",
    "\n",
    "train_gen = augs_gen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size = (224,224),\n",
    "    batch_size=32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_gen = augs_gen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2ef96f27b5123489c3db66426f16816366ff39f"
   },
   "source": [
    "# The Model\n",
    "### Here I use the pretrained mobile net.\n",
    "### I used this architecture because I plan to make this into a web app\n",
    "### https://keras.io/applications/#mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "80f3b87562efe445fb5c0eca507748c51b1f1a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 3,231,939\n",
      "Trainable params: 3,210,051\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base = MobileNet(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "model = Sequential()\n",
    "model.add(model_base)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0,5))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "525c9509fb997b2be96426f56a342ff17540afb0"
   },
   "source": [
    "# Callbacks\n",
    "### Here I load my Keras Callbacks to monitor the training of the model\n",
    "### https://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "69444168ff80c96381a47bf0482023cfa3c92112"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v2.py:92: UserWarning: The TensorBoard callback `batch_size` argument (for histogram computation) is deprecated with TensorFlow 2.0. It will be ignored.\n",
      "  warnings.warn('The TensorBoard callback `batch_size` argument '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v2.py:97: UserWarning: The TensorBoard callback does not support gradients display when using TensorFlow 2.0. The `write_grads` argument is ignored.\n",
      "  warnings.warn('The TensorBoard callback does not support '\n"
     ]
    }
   ],
   "source": [
    "#-------Callbacks-------------#\n",
    "best_model_weights = './base.model'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    best_model_weights,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=False,\n",
    "    period=1\n",
    ")\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir = './logs',\n",
    "    histogram_freq=0,\n",
    "    batch_size=16,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=False,\n",
    ")\n",
    "\n",
    "csvlogger = CSVLogger(\n",
    "    filename= \"training_csv.log\",\n",
    "    separator = \",\",\n",
    "    append = False\n",
    ")\n",
    "\n",
    "#lrsched = LearningRateScheduler(step_decay,verbose=1)\n",
    "\n",
    "reduce = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=40,\n",
    "    verbose=1, \n",
    "    mode='auto',\n",
    "    cooldown=1 \n",
    ")\n",
    "\n",
    "callbacks = [checkpoint,tensorboard,csvlogger,reduce]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0f23f1bd99f3359d4880ba8c4ae74f4d2ea280e"
   },
   "source": [
    "# Train The Model\n",
    "### Here I train our model using fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "72fd3605a604ca990bab8c9e87d89ea3171635aa",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a directory: ./logs\\train; No such file or directory [Op:CreateSummaryFileWriter]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bd23888886af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mcallback_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_callback_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     callbacks.set_params({\n\u001b[0;32m    102\u001b[0m         \u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v2.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;34m\"\"\"Sets Keras model and writes graph if specified.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m   1496\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_writers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_run_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1499\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0msummary_ops_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malways_record_summaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_get_writer\u001b[1;34m(self, writer_name)\u001b[0m\n\u001b[0;32m   1574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwriter_name\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m       \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m       \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummary_ops_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_file_writer_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwriter_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwriter_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mcreate_file_writer_v2\u001b[1;34m(logdir, max_queue, flush_millis, filename_suffix, name)\u001b[0m\n\u001b[0;32m    389\u001b[0m               filename_suffix=filename_suffix),\n\u001b[0;32m    390\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m           v2=True)\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, shared_name, init_op_fn, name, v2)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;31m# TODO(nickfelt): cache other constructed ops in graph mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_op_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_op_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_op_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_summary_ops.py\u001b[0m in \u001b[0;36mcreate_summary_file_writer\u001b[1;34m(writer, logdir, max_queue, flush_millis, filename_suffix, name)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a directory: ./logs\\train; No such file or directory [Op:CreateSummaryFileWriter]"
     ]
    }
   ],
   "source": [
    "opt = SGD(lr=1e-4,momentum=0.99)\n",
    "opt1 = Adam(lr=2e-4)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "    \n",
    "history = model.fit_generator(\n",
    "    train_gen, \n",
    "    steps_per_epoch  = 50, \n",
    "    validation_data  = val_gen,\n",
    "    validation_steps = 50,\n",
    "    epochs = 5, \n",
    "    verbose = 1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2cd33bed7431aeb30921fa01032304b2068bb5a"
   },
   "source": [
    "# Model Evaluation\n",
    "### Here I visualize the training results, load the best model weights, evalute the model, save the json file and h5 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9875bf81a6591348565e02eeaa6d97d99e653883"
   },
   "outputs": [],
   "source": [
    "show_final_history(history)\n",
    "model.load_weights(best_model_weights)\n",
    "model_score = model.evaluate_generator(val_gen,steps=20)\n",
    "print(\"Model Test Loss:\",model_score[0])\n",
    "print(\"Model Test Accuracy:\",model_score[1])\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save(\"model.h5\")\n",
    "print(\"Weights Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a25901b1c24f0bfc1fcdd78ee2e9027b238b08c2"
   },
   "source": [
    "# TensorBoard\n",
    "### Here is a script that you can use with the TensorBoard Keras Callback. It will give you a URL to view your models training results on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6afb297e1b8d691f9d190277c41a04e42325db52"
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "LOG_DIR = './logs' # Here you have to put your log directory\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 8080 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "459994972c915591976a584e31aeea382c3a4f4f"
   },
   "source": [
    "# Happy Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31fa95efdbe84651d34d2192a798030aca45d42b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
